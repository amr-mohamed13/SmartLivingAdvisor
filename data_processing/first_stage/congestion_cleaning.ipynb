{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f207a-5c25-4fad-94ae-c5ffa8c943f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load Dataset ---\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\Project_Data\\us_congestion_2016_2022_sample_2m\\us_congestion_2016_2022_sample_2m.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# --- Cleaning Pipeline ---\n",
    "\"\"\"\n",
    "Cleans congestion dataset:\n",
    "- Fixes datetime columns\n",
    "- Handles missing values in weather-related columns\n",
    "- Drops rows with missing critical traffic/location fields\n",
    "- Creates derived features (Duration_min, numeric congestion speed)\n",
    "\"\"\"\n",
    "\n",
    "# --- 1. Fix datetime columns ---\n",
    "for col in ['StartTime', 'EndTime', 'WeatherTimeStamp']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "\n",
    "# --- 2. Derived feature: Duration (in minutes) ---\n",
    "if 'StartTime' in df.columns and 'EndTime' in df.columns:\n",
    "    df['Duration_min'] = (df['EndTime'] - df['StartTime']).dt.total_seconds() / 60\n",
    "    df['Duration_min'] = df['Duration_min'].fillna(0)\n",
    "\n",
    "# --- 3. Numeric conversion ---\n",
    "num_cols = [\n",
    "    'Severity', 'Distance(mi)', 'DelayFromTypicalTraffic(mins)',\n",
    "    'DelayFromFreeFlowSpeed(mins)', 'Temperature(F)', 'WindChill(F)',\n",
    "    'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'WindSpeed(mph)',\n",
    "    'Precipitation(in)'\n",
    "]\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# --- 4. Handle Missing Values ---\n",
    "# Drop rows if critical columns are missing\n",
    "critical_cols = [\n",
    "    'ID', 'City', 'State', 'Country', 'StartTime', 'EndTime',\n",
    "    'DelayFromTypicalTraffic(mins)', 'Congestion_Speed'\n",
    "]\n",
    "df = df.dropna(subset=[col for col in critical_cols if col in df.columns])\n",
    "\n",
    "# Weather-related columns\n",
    "if 'Temperature(F)' in df.columns:\n",
    "    df['Temperature(F)'] = df.groupby('City')['Temperature(F)'].transform(lambda x: x.fillna(x.mean()))\n",
    "if 'Humidity(%)' in df.columns:\n",
    "    df['Humidity(%)'] = df.groupby('City')['Humidity(%)'].transform(lambda x: x.fillna(x.mean()))\n",
    "if 'Weather_Event' in df.columns:\n",
    "    df['Weather_Event'] = df['Weather_Event'].fillna(\"None\")\n",
    "if 'Weather_Conditions' in df.columns:\n",
    "    df['Weather_Conditions'] = (\n",
    "        df['Weather_Conditions'].astype(str).str.strip().str.lower().replace(\"nan\", np.nan).fillna(\"Unknown\")\n",
    "    )\n",
    "\n",
    "# --- 5. Numeric encoding for Congestion_Speed ---\n",
    "speed_map = {'Very Slow': 5, 'Slow': 10, 'Moderate': 20, 'Fast': 30}\n",
    "if 'Congestion_Speed' in df.columns:\n",
    "    df['Congestion_Speed_num'] = df['Congestion_Speed'].map(speed_map)\n",
    "\n",
    "# --- 6. Drop duplicates by ID ---\n",
    "df = df.drop_duplicates(subset=['ID'])\n",
    "\n",
    "# --- 7. Save Cleaned Dataset ---\n",
    "output_path = r\"D:\\Project_Data\\Processed Data\\cleaned_congestion.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Cleaning complete. Saved cleaned dataset to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
