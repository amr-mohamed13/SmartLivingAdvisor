{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e2a654-7835-46ea-b225-240af38e4f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning complete. Saved cleaned dataset to: D:\\DEPI_Project\\Datasets\\Cleaned\\Population and Anuual Income\\cleaned_population_and_annual_income.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load Dataset ---\n",
    "df = pd.read_csv(\n",
    "    r\"D:\\DEPI_Project\\Datasets\\Raw\\Population and Anuual Income\\census_tracts_all_states_with_names.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# --- Cleaning Pipeline ---\n",
    "\"\"\"\n",
    "Cleans census (demographics) dataset:\n",
    "- Ensures correct numeric types\n",
    "- Splits 'name' field into separate columns (tract, county, state)\n",
    "- Creates a unified district identifier (FIPS)\n",
    "- Handles missing values\n",
    "- Removes duplicates\n",
    "\"\"\"\n",
    "\n",
    "# --- 1. Fix Data Types ---\n",
    "num_cols = [\"state_fips\", \"county_fips\", \"tract_fips\", \"income\", \"population\"]\n",
    "for col in num_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# --- 2. Split 'name' Column ---\n",
    "if \"name\" in df.columns:\n",
    "    # Expected format: \"Census Tract 201; Autauga County; Alabama\"\n",
    "    name_parts = df[\"name\"].astype(str).str.split(\"; \", expand=True)\n",
    "    df[\"tract_name\"] = name_parts[0].str.replace(\"Census Tract \", \"\", regex=False).str.strip()\n",
    "    df[\"county_name\"] = name_parts[1].str.replace(\" County\", \"\", regex=False).str.strip()\n",
    "    df[\"state_name\"] = name_parts[2].str.strip()\n",
    "\n",
    "# --- 3. Generate Unified FIPS ID ---\n",
    "# Combines state, county, and tract FIPS codes into one unique district ID\n",
    "df[\"district_fips_id\"] = (\n",
    "    df[\"state_fips\"].astype(str).str.zfill(2)\n",
    "    + df[\"county_fips\"].astype(str).str.zfill(3)\n",
    "    + df[\"tract_fips\"].astype(str).str.zfill(6)\n",
    ")\n",
    "\n",
    "# --- 4. Handle Missing Values ---\n",
    "# Drop rows with missing essential geographic or population info\n",
    "critical_cols = [\"district_fips_id\", \"state_name\", \"county_name\", \"tract_name\", \"population\"]\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "# Fill missing income with the median for that state\n",
    "if \"income\" in df.columns and \"state_name\" in df.columns:\n",
    "    df[\"income\"] = df.groupby(\"state_name\")[\"income\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# --- 5. Remove Duplicates ---\n",
    "df = df.drop_duplicates(subset=[\"district_fips_id\"])\n",
    "\n",
    "# --- 6. Save Cleaned Dataset ---\n",
    "output_path = r\"D:\\DEPI_Project\\Datasets\\Cleaned\\Population and Anuual Income\\cleaned_population_and_annual_income.csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Cleaning complete. Saved cleaned dataset to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de572ec1-7ae8-45e2-afb2-912b02dc2748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
